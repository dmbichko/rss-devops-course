name: Terraform Deployment

on:
  pull_request:
  push:
    branches:
#      - dev
      - dev_task3

env:
  AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
  EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
  BASTION_SSH_KEY: ${{ secrets.BASTION_SSH_KEY }}
  K3S_TOKEN: ${{secrets.K3S_TOKEN}}
  TERRAFORM_VERSION: 1.9.6
  AWS_REGION: us-east-1
  GITHUB_ACTIONS_ROLE_NAME: GithubActionsRole

permissions:
  id-token: write
  contents: read

jobs:

  terraform-init:
    name: Terraform Init
    runs-on: ubuntu-latest
    steps:
      - name: Checkout the code
        uses: actions/checkout@v4
  
      - name: Configure AWS credentials using OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/${{ env.GITHUB_ACTIONS_ROLE_NAME }} 
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }} 
      
      - name: Terraform Init
        run: terraform init

      - name: Cache Terraform modules
        uses: actions/cache@v4
        with:
          path: |
            ~/.terraform
            .terraform*        
          key: ${{ runner.os }}-terraform-${{ hashFiles('**/*.tf') }}
          restore-keys: |
            ${{ runner.os }}-terraform-

  terraform-fmt:
    name: Terraform Format 
    runs-on: ubuntu-latest
    needs: terraform-init

    steps:
      - name: Checkout the code
        uses: actions/checkout@v4

      - name: Terraform Format 
        run: terraform fmt -check -recursive
        continue-on-error: false

  terraform-plane:
    name: Terraform Plan
    runs-on: ubuntu-latest
    needs: terraform-fmt
    
    steps:
      - name: Checkout the code
        uses: actions/checkout@v4

      - name: Restore Terraform cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.terraform
            .terraform*    
          key: ${{ runner.os }}-terraform-${{ hashFiles('**/*.tf') }}
          restore-keys: |
            ${{ runner.os }}-terraform- 

      - name: Configure AWS credentials using OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/${{ env.GITHUB_ACTIONS_ROLE_NAME }}  
          aws-region: ${{ env.AWS_REGION }}
      - name: Terraform unlock
        run: terraform force-unlock e586250e-c96a-97f4-bf1c-118f928c1687 
      - name: Terraform Plan
        run: terraform plan -input=false -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" -var="bastion-ssh-key=${{ env.BASTION_SSH_KEY }}" -var="ec2-ssh-key=${{ env.EC2_SSH_KEY }}" -var="k3s_token=${{env.K3S_TOKEN}}"

  terraform-apply:
          name: Terraform Apply
          runs-on: ubuntu-latest
          needs: terraform-plane
          
          steps:
            - name: Checkout the code
              uses: actions/checkout@v4
      
            - name: Restore Terraform cache
              uses: actions/cache@v4
              with:
                path: |
                  ~/.terraform
                  .terraform*    
                key: ${{ runner.os }}-terraform-${{ hashFiles('**/*.tf') }}
                restore-keys: |
                  ${{ runner.os }}-terraform- 
      
            - name: Configure AWS credentials using OIDC
              uses: aws-actions/configure-aws-credentials@v4
              with:
                role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/${{ env.GITHUB_ACTIONS_ROLE_NAME }}  
                aws-region: ${{ env.AWS_REGION }}
      
            - name: Terraform Apply
              run: terraform apply -auto-approve -var="aws_account_id=${{ env.AWS_ACCOUNT_ID }}" -var="bastion-ssh-key=${{ env.BASTION_SSH_KEY }}" -var="ec2-ssh-key=${{ env.EC2_SSH_KEY }}" -var="k3s_token=${{env.K3S_TOKEN}}"

            - name: Get Terraform outputs
              run: |
                echo "K3S_SERVER_ID=$(terraform output -raw k3s_server_id || echo '')" >> $GITHUB_ENV
                echo "BASTION_HOST_ID=$(terraform output -raw bastion_server_id || echo '')" >> $GITHUB_ENV
            - name: Install or update AWS CLI and Session Manager plugin
              run: |
                    if [ -f "/usr/local/bin/aws" ]; then
                      echo "AWS CLI is already installed. Updating..."
                      curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                      unzip -q awscliv2.zip
                      sudo ./aws/install --update
                    else
                      echo "Installing AWS CLI..."
                      curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                      unzip -q awscliv2.zip
                      sudo ./aws/install
                    fi
                    
                    if ! command -v session-manager-plugin &> /dev/null; then
                      echo "Installing Session Manager plugin..."
                      curl "https://s3.amazonaws.com/session-manager-downloads/plugin/latest/ubuntu_64bit/session-manager-plugin.deb" -o "session-manager-plugin.deb"
                      sudo dpkg -i session-manager-plugin.deb
                    else
                      echo "Session Manager plugin is already installed."
                    fi
                    
                    # Clean up
                    rm -rf aws awscliv2.zip session-manager-plugin.deb
 
            - name: Copy K3s config to bastion host
              run: |
                if [ -z "$K3S_SERVER_ID" ] || [ -z "$BASTION_HOST_ID" ]; then
                  echo "K3s server ID or Bastion host ID not found. Skipping config copy."
                else
                  echo "Fetching K3s config from control server..."
                  K3S_CONFIG=$(aws ssm send-command \
                    --instance-ids $K3S_SERVER_ID \
                    --document-name "AWS-RunShellScript" \
                    --parameters '{"commands":["sudo cat /etc/rancher/k3s/k3s.yaml"]}' \
                    --output text \
                    --query "Commands[0].CommandId")
            
                  # Wait for the command to complete
                  aws ssm wait command-executed --command-id $K3S_CONFIG --instance-id $K3S_SERVER_ID
            
                  # Fetch the config content
                  CONFIG_CONTENT=$(aws ssm get-command-invocation \
                    --command-id $K3S_CONFIG \
                    --instance-id $K3S_SERVER_ID \
                    --query "StandardOutputContent" \
                    --output text)
            
                  # Replace the server address with the public IP or DNS of your K3s server
                  K3S_SERVER_IP=$(aws ec2 describe-instances --instance-ids $K3S_SERVER_ID --query 'Reservations[0].Instances[0].PublicIpAddress' --output text)
                  CONFIG_CONTENT=$(echo "$CONFIG_CONTENT" | sed "s/127.0.0.1/$K3S_SERVER_IP/")
            
                  echo "Copying K3s config to bastion host..."
                  aws ssm send-command \
                    --instance-ids $BASTION_HOST_ID \
                    --document-name "AWS-RunShellScript" \
                    --parameters "{\"commands\":[\"echo '$CONFIG_CONTENT' > ~/.kube/config\", \"chmod 600 ~/.kube/config\"]}" \
                    --output text
            
                  echo "K3s config copied to bastion host."
                fi
              env:
                K3S_SERVER_ID: ${{ env.K3S_SERVER_ID }}
                BASTION_HOST_ID: ${{ env.BASTION_HOST_ID }}                 
                    
#            - name: Label K3s worker nodes
#              run: |
#                if [ -z "$K3S_SERVER_ID" ]; then
#                  echo "K3s server ID not found. Skipping node labeling."
#                else
#                  echo "Labeling worker nodes on K3s server..."
#                  aws ssm send-command \
#                    --instance-ids $K3S_SERVER_ID \
#                    --document-name "AWS-RunShellScript" \
#                    --parameters '{
#                      "commands": [
#                        "sudo kubectl get nodes -o custom-columns=NAME:.metadata.name,ROLES:.metadata.labels.node-role\\.kubernetes\\.io/master | grep \"<none>\" | awk \"{print \\$1}\" | while read node; do sudo kubectl label node $node node-role.kubernetes.io/worker=worker --overwrite; done"
#                      ]
#                    }'
#            
#                  # Wait for the command to complete
#                  sleep 10
#            
#                  # Check the command output
#                  COMMAND_ID=$(aws ssm list-commands --instance-id $K3S_SERVER_ID --query "Commands[0].CommandId" --output text)
#                  aws ssm get-command-invocation --command-id $COMMAND_ID --instance-id $K3S_SERVER_ID --output text
#                fi
                  
              


              
